"""
æ§‹é€ ä»•æ§˜ãƒ™ãƒ¼ã‚¹ã®ã‚³ãƒ¼ãƒ‰ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆãƒ»æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ  - ã‚³ã‚¢ã‚¨ãƒ³ã‚¸ãƒ³
"""

from __future__ import annotations

import importlib
import json
import sys
from pathlib import Path
from typing import Any, Generic, TypeVar

import jsonschema
import networkx as nx
import yaml
from pydantic import BaseModel, Field, field_validator


# ==================== åž‹ã‚¢ãƒŽãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒžãƒ¼ã‚«ãƒ¼ ====================

T = TypeVar("T")


class Check(Generic[T]):
    """åž‹ã‚¢ãƒŽãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®Checkå‚ç…§ãƒžãƒ¼ã‚«ãƒ¼

    Usage:
        Annotated[Out, Check["module.path.check_function"]]
    """

    def __class_getitem__(cls, item: str) -> type:
        """æ–‡å­—åˆ—ã§ãƒã‚§ãƒƒã‚¯é–¢æ•°ã‚’å‚ç…§"""
        return type(f"Check[{item}]", (), {"__check_ref__": item})


class ExampleValue(Generic[T]):
    """åž‹ã‚¢ãƒŽãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®Exampleå€¤ãƒžãƒ¼ã‚«ãƒ¼

    Usage:
        Annotated[In, ExampleValue[{"text": "hello world"}]]
    """

    def __class_getitem__(cls, item: dict[str, Any]) -> type:
        """è¾žæ›¸ã§ä¾‹ç¤ºå€¤ã‚’å‚ç…§"""
        return type(f"ExampleValue[{item}]", (), {"__example_value__": item})


# ==================== ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å®šç¾© ====================


class CheckDef(BaseModel):
    """ãƒã‚§ãƒƒã‚¯é–¢æ•°å®šç¾©"""

    id: str
    description: str
    impl: str  # "module:function"å½¢å¼
    file_path: str


class Example(BaseModel):
    """æ¤œè¨¼ç”¨å…¥åŠ›ãƒ»æœŸå¾…å€¤å®šç¾©"""

    id: str
    description: str
    input: dict[str, Any]
    expected: dict[str, Any]


class DataType(BaseModel):
    """ãƒ‡ãƒ¼ã‚¿æ§‹é€ å®šç¾©"""

    model_config = {"protected_namespaces": (), "use_attribute_docstrings": True}

    id: str
    description: str
    check_ids: list[str] = Field(default_factory=list)
    example_ids: list[str] = Field(default_factory=list)
    schema: dict[str, Any]  # JSON Schema


class Parameter(BaseModel):
    """é–¢æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®šç¾©"""

    name: str
    datatype_ref: str | None = None
    native: str | None = None  # "builtins:type"å½¢å¼

    @field_validator("datatype_ref", "native")
    @classmethod
    def at_least_one(cls, v: str | None, info) -> str | None:
        values = info.data
        if "datatype_ref" in values and "native" in values:
            if values.get("datatype_ref") is None and values.get("native") is None:
                raise ValueError("datatype_ref ã¾ãŸã¯ native ã®ã„ãšã‚Œã‹ãŒå¿…è¦ã§ã™")
        return v


class Transform(BaseModel):
    """å‡¦ç†é–¢æ•°å®šç¾©"""

    id: str
    description: str
    impl: str  # "module:function"å½¢å¼
    file_path: str
    parameters: list[Parameter]
    return_datatype_ref: str | None = None
    default_args: dict[str, Any] = Field(default_factory=dict)


class DAGEdge(BaseModel):
    """DAGã‚¨ãƒƒã‚¸å®šç¾©"""

    model_config = {"populate_by_name": True}

    from_: str = Field(alias="from")
    to: str | None


class Meta(BaseModel):
    """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿"""

    name: str
    description: str


class Spec(BaseModel):
    """ä»•æ§˜å…¨ä½“ã®ãƒ«ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«"""

    version: str
    meta: Meta
    checks: list[CheckDef] = Field(default_factory=list)
    examples: list[Example] = Field(default_factory=list)
    datatypes: list[DataType] = Field(default_factory=list)
    transforms: list[Transform] = Field(default_factory=list)
    dag: list[DAGEdge] = Field(default_factory=list)


# ==================== ä»•æ§˜èª­ã¿è¾¼ã¿ãƒ»æ¤œè¨¼ ====================


def load_spec(spec_path: str | Path) -> Spec:
    """YAML/JSONä»•æ§˜ã‚’èª­ã¿è¾¼ã¿ã€Pydanticã§æ¤œè¨¼"""
    spec_path = Path(spec_path)
    with open(spec_path) as f:
        if spec_path.suffix in [".yaml", ".yml"]:
            data = yaml.safe_load(f)
        elif spec_path.suffix == ".json":
            data = json.load(f)
        else:
            raise ValueError(f"æœªå¯¾å¿œã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {spec_path.suffix}")

    return Spec(**data)


# ==================== ã‚¹ã‚±ãƒ«ãƒˆãƒ³ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ ====================


def _build_type_annotation(
    spec: Spec, param: Parameter, app_root: Path
) -> tuple[str, set[str]]:
    """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åž‹ã‚¢ãƒŽãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰

    Returns:
        (åž‹æ–‡å­—åˆ—, importã‚»ãƒƒãƒˆ)
    """
    imports = set()

    if param.datatype_ref:
        # DataTypeå‚ç…§ã‚’è§£æ±º
        datatype = next((dt for dt in spec.datatypes if dt.id == param.datatype_ref), None)
        if not datatype:
            return "dict", imports

        # Checkå‚ç…§ã‚’è¿½åŠ 
        check_annotations = []
        for check_id in datatype.check_ids:
            check_def = next((c for c in spec.checks if c.id == check_id), None)
            if check_def:
                check_annotations.append(f'Check["{check_def.impl}"]')
                imports.add("from spec2code.engine import Check")

        # Exampleå‚ç…§ã‚’è¿½åŠ 
        example_annotations = []
        for example_id in datatype.example_ids:
            example = next((e for e in spec.examples if e.id == example_id), None)
            if example:
                example_annotations.append(f"ExampleValue[{example.input}]")
                imports.add("from spec2code.engine import ExampleValue")

        # Annotatedã‚’ä½¿ç”¨
        if check_annotations or example_annotations:
            imports.add("from typing import Annotated")
            annotations = ", ".join(check_annotations + example_annotations)
            return f"Annotated[dict, {annotations}]", imports

        return "dict", imports

    elif param.native:
        # ãƒã‚¤ãƒ†ã‚£ãƒ–åž‹ã‚’è§£æ±º
        _, type_name = param.native.split(":")
        return type_name, imports

    return "Any", {"from typing import Any"}


def _build_return_annotation(
    spec: Spec, transform: Transform, app_root: Path
) -> tuple[str, set[str]]:
    """æˆ»ã‚Šå€¤ã®åž‹ã‚¢ãƒŽãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰

    Returns:
        (åž‹æ–‡å­—åˆ—, importã‚»ãƒƒãƒˆ)
    """
    imports = set()

    if not transform.return_datatype_ref:
        return "dict", imports

    datatype = next(
        (dt for dt in spec.datatypes if dt.id == transform.return_datatype_ref), None
    )
    if not datatype:
        return "dict", imports

    # Checkå‚ç…§ã‚’è¿½åŠ 
    check_annotations = []
    for check_id in datatype.check_ids:
        check_def = next((c for c in spec.checks if c.id == check_id), None)
        if check_def:
            check_annotations.append(f'Check["{check_def.impl}"]')
            imports.add("from spec2code.engine import Check")

    # Annotatedã‚’ä½¿ç”¨
    if check_annotations:
        imports.add("from typing import Annotated")
        annotations = ", ".join(check_annotations)
        return f"Annotated[dict, {annotations}]", imports

    return "dict", imports


def generate_skeleton(spec: Spec, project_root: Path = Path(".")) -> None:
    """æœªå®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•ç”Ÿæˆ"""
    print("ðŸ”¨ Generating skeleton code...")

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã«åŸºã¥ãå‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    app_root = project_root / "apps" / spec.meta.name
    print(f"  ðŸ“ Target directory: {app_root}")

    # Checké–¢æ•°ã®ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ
    for check in spec.checks:
        file_path = app_root / check.file_path
        if file_path.exists():
            print(f"  â­ï¸  Skip (exists): {file_path}")
            continue

        file_path.parent.mkdir(parents=True, exist_ok=True)
        func_name = check.impl.split(":")[-1]

        code = f'''# Auto-generated skeleton for Check: {check.id}
def {func_name}(payload: dict) -> bool:
    """{check.description}"""
    # TODO: implement validation logic
    return True
'''
        file_path.write_text(code)
        print(f"  âœ… Generated: {file_path}")

    # Transformé–¢æ•°ã®ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ
    for transform in spec.transforms:
        file_path = app_root / transform.file_path
        if file_path.exists():
            print(f"  â­ï¸  Skip (exists): {file_path}")
            continue

        file_path.parent.mkdir(parents=True, exist_ok=True)
        func_name = transform.impl.split(":")[-1]

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åž‹ã‚¢ãƒŽãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰
        param_strs = []
        all_imports = set()

        for param in transform.parameters:
            type_str, imports = _build_type_annotation(spec, param, app_root)
            all_imports.update(imports)
            param_strs.append(f"{param.name}: {type_str}")

        # æˆ»ã‚Šå€¤ã®åž‹ã‚¢ãƒŽãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰
        return_type, return_imports = _build_return_annotation(spec, transform, app_root)
        all_imports.update(return_imports)

        # importæ–‡ã‚’ç”Ÿæˆï¼ˆspec2code.engineã‹ã‚‰ã®importã‚’çµ±åˆï¼‰
        import_lines = []
        spec2code_imports = set()
        other_imports = set()

        for imp in all_imports:
            if imp.startswith("from spec2code.engine import"):
                # spec2code.engineã‹ã‚‰ã®importã‚’æŠ½å‡º
                parts = imp.split("import", 1)[1].strip()
                spec2code_imports.add(parts)
            else:
                other_imports.add(imp)

        # spec2code.engineã®importã‚’çµ±åˆ
        if spec2code_imports:
            combined_import = f"from spec2code.engine import {', '.join(sorted(spec2code_imports))}"
            import_lines.append(combined_import)

        # ãã®ä»–ã®importã‚’è¿½åŠ 
        import_lines.extend(sorted(other_imports))

        import_section = "\n".join(import_lines) if import_lines else ""

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆä½œæˆ
        params = ", ".join(param_strs)

        code = f'''# Auto-generated skeleton for Transform: {transform.id}
{import_section}

def {func_name}({params}) -> {return_type}:
    """{transform.description}"""
    # TODO: implement transform logic
    return {{}}
'''
        file_path.write_text(code)
        print(f"  âœ… Generated: {file_path}")

    # __init__.py ã‚’å„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä½œæˆ
    for directory in ["checks", "transforms", "datatypes"]:
        init_path = app_root / directory / "__init__.py"
        if not init_path.exists():
            init_path.parent.mkdir(parents=True, exist_ok=True)
            init_path.write_text("# Auto-generated\n")
            print(f"  âœ… Generated: {init_path}")


# ==================== DAGæ¤œè¨¼ãƒ»å®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³ ====================


class Engine:
    """ã‚³ã‚¢å®Ÿè¡Œãƒ»æ¤œè¨¼ãƒ»ç”Ÿæˆã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self, spec: Spec):
        self.spec = spec
        self.graph = self._build_dag()

    def _build_dag(self) -> nx.DiGraph:
        """DAGã‚’æ§‹ç¯‰"""
        g = nx.DiGraph()

        # Transformã‚’ãƒŽãƒ¼ãƒ‰ã¨ã—ã¦è¿½åŠ 
        for transform in self.spec.transforms:
            g.add_node(transform.id)

        # ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ 
        for edge in self.spec.dag:
            if edge.to is None:
                # çµ‚ç«¯ãƒŽãƒ¼ãƒ‰
                continue
            g.add_edge(edge.from_, edge.to)

        # DAGæ¤œè¨¼ï¼ˆã‚µã‚¤ã‚¯ãƒ«ãŒãªã„ã‹ï¼‰
        if not nx.is_directed_acyclic_graph(g):
            raise ValueError("âŒ DAGã«ã‚µã‚¤ã‚¯ãƒ«ãŒå­˜åœ¨ã—ã¾ã™")

        return g

    def validate_schemas(self) -> None:
        """JSON Schemaæ¤œè¨¼"""
        print("ðŸ” Validating schemas...")
        for datatype in self.spec.datatypes:
            try:
                # ã‚¹ã‚­ãƒ¼ãƒžè‡ªä½“ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
                jsonschema.Draft7Validator.check_schema(datatype.schema)
                print(f"  âœ… {datatype.id}: schema valid")
            except jsonschema.SchemaError as e:
                print(f"  âŒ {datatype.id}: schema invalid - {e}")

    def validate_integrity(self, project_root: Path = Path(".")) -> dict[str, list[str]]:
        """ä»•æ§˜ã¨å®Ÿè£…ã®æ•´åˆæ€§ã‚’æ¤œè¨¼

        Returns:
            ã‚¨ãƒ©ãƒ¼ãƒžãƒƒãƒ— {category: [error_messages]}
        """
        print("ðŸ” Validating spec-implementation integrity...")
        errors: dict[str, list[str]] = {
            "check_functions": [],
            "check_locations": [],
            "transform_functions": [],
            "transform_signatures": [],
            "example_schemas": [],
        }

        # sys.pathã«packagesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿½åŠ 
        packages_dir = str((project_root / "packages").resolve())
        if packages_dir not in sys.path:
            sys.path.insert(0, packages_dir)

        app_root = project_root / "apps" / self.spec.meta.name

        # 1. Checké–¢æ•°ã®å­˜åœ¨ã¨ä½ç½®ã‚’æ¤œè¨¼
        for check in self.spec.checks:
            module_path, func_name = check.impl.split(":")
            expected_file = app_root / check.file_path

            # é–¢æ•°ãŒèª­ã¿è¾¼ã‚ã‚‹ã‹
            try:
                module = importlib.import_module(module_path)
                func = getattr(module, func_name)
                print(f"  âœ… Check {check.id}: function exists")

                # ãƒ•ã‚¡ã‚¤ãƒ«ä½ç½®ã®æ¤œè¨¼
                import inspect
                actual_file = Path(inspect.getfile(func)).resolve()
                expected_file_resolved = expected_file.resolve()

                if actual_file != expected_file_resolved:
                    error_msg = (
                        f"Check '{check.id}' location mismatch:\n"
                        f"    Expected: {expected_file}\n"
                        f"    Actual:   {actual_file}"
                    )
                    errors["check_locations"].append(error_msg)
                    print(f"  âš ï¸  {error_msg}")

            except (ImportError, AttributeError) as e:
                error_msg = f"Check '{check.id}' not found: {e}"
                errors["check_functions"].append(error_msg)
                print(f"  âŒ {error_msg}")

        # 2. Transformé–¢æ•°ã®å­˜åœ¨ã¨ä½ç½®ã‚’æ¤œè¨¼
        for transform in self.spec.transforms:
            module_path, func_name = transform.impl.split(":")
            expected_file = app_root / transform.file_path

            try:
                module = importlib.import_module(module_path)
                func = getattr(module, func_name)
                print(f"  âœ… Transform {transform.id}: function exists")

                # ãƒ•ã‚¡ã‚¤ãƒ«ä½ç½®ã®æ¤œè¨¼
                import inspect
                actual_file = Path(inspect.getfile(func)).resolve()
                expected_file_resolved = expected_file.resolve()

                if actual_file != expected_file_resolved:
                    error_msg = (
                        f"Transform '{transform.id}' location mismatch:\n"
                        f"    Expected: {expected_file}\n"
                        f"    Actual:   {actual_file}"
                    )
                    errors["transform_functions"].append(error_msg)
                    print(f"  âš ï¸  {error_msg}")

                # ã‚·ã‚°ãƒãƒãƒ£ã®æ¤œè¨¼
                sig = inspect.signature(func)
                expected_params = {p.name for p in transform.parameters}
                actual_params = set(sig.parameters.keys())

                if expected_params != actual_params:
                    error_msg = (
                        f"Transform '{transform.id}' signature mismatch:\n"
                        f"    Expected params: {sorted(expected_params)}\n"
                        f"    Actual params:   {sorted(actual_params)}"
                    )
                    errors["transform_signatures"].append(error_msg)
                    print(f"  âš ï¸  {error_msg}")

            except (ImportError, AttributeError) as e:
                error_msg = f"Transform '{transform.id}' not found: {e}"
                errors["transform_functions"].append(error_msg)
                print(f"  âŒ {error_msg}")

        # 3. Exampleå€¤ã®ã‚¹ã‚­ãƒ¼ãƒžé©åˆæ€§ã‚’æ¤œè¨¼
        for example in self.spec.examples:
            # ã“ã®ExampleãŒå‚ç…§ã•ã‚Œã¦ã„ã‚‹DataTypeã‚’æŽ¢ã™
            for datatype in self.spec.datatypes:
                if example.id in datatype.example_ids:
                    try:
                        jsonschema.validate(example.input, datatype.schema)
                        print(f"  âœ… Example {example.id}: schema valid for {datatype.id}")
                    except jsonschema.ValidationError as e:
                        error_msg = (
                            f"Example '{example.id}' invalid for DataType '{datatype.id}':\n"
                            f"    {e.message}"
                        )
                        errors["example_schemas"].append(error_msg)
                        print(f"  âŒ {error_msg}")

        # ã‚µãƒžãƒªãƒ¼è¡¨ç¤º
        total_errors = sum(len(errs) for errs in errors.values())
        if total_errors == 0:
            print("\nâœ… All integrity checks passed!")
        else:
            print(f"\nâš ï¸  Found {total_errors} integrity issue(s)")

        return errors

    def run_checks(self) -> None:
        """Checké–¢æ•°ã‚’å®Ÿè¡Œ"""
        print("ðŸ” Running checks...")
        for check in self.spec.checks:
            module_path, func_name = check.impl.split(":")
            try:
                module = importlib.import_module(module_path)
                getattr(module, func_name)
                print(f"  âœ… {check.id}: loaded")
            except (ImportError, AttributeError) as e:
                print(f"  âŒ {check.id}: {e}")

    def run_examples(self) -> dict[str, bool]:
        """Exampleæ¤œè¨¼ã‚’å®Ÿè¡Œ"""
        print("ðŸ§ª Running examples...")
        results = {}

        for example in self.spec.examples:
            # ç°¡æ˜“å®Ÿè£…: Transformã‚’å®Ÿè¡Œã—ã¦æœŸå¾…å€¤ã¨æ¯”è¼ƒ
            # å®Ÿéš›ã«ã¯DAGã‚’è¾¿ã£ã¦å®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚‹
            print(f"  ðŸ”¬ {example.id}: {example.description}")
            results[example.id] = True  # TODO: å®Ÿéš›ã®æ¤œè¨¼ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…

        return results

    def run_dag(self) -> None:
        """DAGã‚’å®Ÿè¡Œ"""
        print("ðŸš€ Running DAG...")

        if len(self.graph.nodes) == 0:
            print("  â„¹ï¸  No transforms to execute")
            return

        # ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ã‚½ãƒ¼ãƒˆã§å®Ÿè¡Œé †åºã‚’æ±ºå®š
        try:
            execution_order = list(nx.topological_sort(self.graph))
        except nx.NetworkXError:
            print("  âŒ Cannot determine execution order (cycle detected)")
            return

        for transform_id in execution_order:
            # Transformå®šç¾©ã‚’å–å¾—
            transform = next(
                (t for t in self.spec.transforms if t.id == transform_id), None
            )
            if not transform:
                print(f"  âŒ {transform_id}: not found in spec")
                continue

            # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»é–¢æ•°ã‚’ãƒ­ãƒ¼ãƒ‰
            module_path, func_name = transform.impl.split(":")
            try:
                module = importlib.import_module(module_path)
                func = getattr(module, func_name)

                # ç°¡æ˜“å®Ÿè¡Œï¼ˆå¼•æ•°ã¯ä»®ï¼‰
                # å®Ÿéš›ã«ã¯ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè£…ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
                result = func(**transform.default_args)
                print(f"  âœ… {transform_id} -> {result}")
            except (ImportError, AttributeError) as e:
                print(f"  âŒ {transform_id}: {e}")
            except Exception as e:
                print(f"  âŒ {transform_id}: execution error - {e}")


# ==================== CLI ====================


def main():
    """CLIã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    import argparse

    parser = argparse.ArgumentParser(description="Spec-to-Code Engine")
    subparsers = parser.add_subparsers(dest="command", help="ã‚µãƒ–ã‚³ãƒžãƒ³ãƒ‰")

    # gen ã‚³ãƒžãƒ³ãƒ‰
    gen_parser = subparsers.add_parser("gen", help="ã‚¹ã‚±ãƒ«ãƒˆãƒ³ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ")
    gen_parser.add_argument("spec_file", help="ä»•æ§˜ãƒ•ã‚¡ã‚¤ãƒ« (YAML/JSON)")

    # run ã‚³ãƒžãƒ³ãƒ‰
    run_parser = subparsers.add_parser("run", help="DAGå®Ÿè¡Œãƒ»æ¤œè¨¼")
    run_parser.add_argument("spec_file", help="ä»•æ§˜ãƒ•ã‚¡ã‚¤ãƒ« (YAML/JSON)")

    # validate ã‚³ãƒžãƒ³ãƒ‰
    validate_parser = subparsers.add_parser(
        "validate", help="ä»•æ§˜ã¨å®Ÿè£…ã®æ•´åˆæ€§ã‚’æ¤œè¨¼"
    )
    validate_parser.add_argument("spec_file", help="ä»•æ§˜ãƒ•ã‚¡ã‚¤ãƒ« (YAML/JSON)")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    # ä»•æ§˜èª­ã¿è¾¼ã¿
    try:
        spec = load_spec(args.spec_file)
        print(f"âœ… Loaded spec: {spec.meta.name} (v{spec.version})")
    except Exception as e:
        print(f"âŒ Failed to load spec: {e}")
        sys.exit(1)

    # ã‚³ãƒžãƒ³ãƒ‰å®Ÿè¡Œ
    if args.command == "gen":
        generate_skeleton(spec)
        print("âœ… Skeleton generation completed")

    elif args.command == "run":
        engine = Engine(spec)
        engine.validate_schemas()
        engine.run_checks()
        engine.run_dag()
        results = engine.run_examples()
        print(f"ðŸ“Š Example report: {results}")
        print("âœ… Execution completed")

    elif args.command == "validate":
        engine = Engine(spec)
        errors = engine.validate_integrity()

        # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°çµ‚äº†ã‚³ãƒ¼ãƒ‰1ã§çµ‚äº†
        total_errors = sum(len(errs) for errs in errors.values())
        if total_errors > 0:
            sys.exit(1)


if __name__ == "__main__":
    main()
