version: "1"
meta:
  name: "algo_trade_pipeline"
  description: "Algorithmic trading DAG pipeline with advanced type features"

checks:
  # Phase 1: Market Data Ingestion
  - id: check_multiasset_frame
    description: "Validate MultiAsset OHLCV frame with MultiIndex structure and detect anomalies"
    impl: "apps.algo_trade_pipeline.checks.market_data_checks:check_multiasset_frame"
    file_path: "checks/market_data_checks.py"
    input_type_ref: MultiAssetOHLCVFrame
    spec_metadata:
      logic_steps:
        - "df.columns が MultiIndex か確認（df.columns.nlevels == 2）"
        - "第1レベルが symbol、第2レベルが OHLCV列名であることを確認"
        - "各 symbol のデータ行数が一致しているか確認（unstack後の形状チェック）"
        - "np.isnan(df).any() および np.isinf(df).any() で異常値検出"
        - "df.index.is_monotonic_increasing で時系列順序確認"
        - "df.pct_change().abs() > 0.5 で極端な価格変動を検出"
      implementation_hints:
        - "MultiIndex操作: df.columns.get_level_values(0/1) で各レベル取得"
        - "行数チェック: df.groupby(level=0, axis=1).size() で各symbolの列数確認"
        - "異常値検出: pandas標準関数とnumpyの組み合わせで効率的にチェック"

  # Phase 2: Feature Engineering
  - id: check_ohlcv
    description: "Validate OHLCV price constraints and detect temporal anomalies"
    impl: "apps.algo_trade_pipeline.checks.feature_checks:check_ohlcv"
    file_path: "checks/feature_checks.py"
    input_type_ref: OHLCVFrame
    spec_metadata:
      logic_steps:
        - "np.isinf(df.select_dtypes(include=[np.number])).any().any() で Inf値検出"
        - "df.index.duplicated().any() でインデックス重複チェック"
        - "(df['high'] >= df[['open', 'close']].max(axis=1)).all() で価格上限制約"
        - "(df['low'] <= df[['open', 'close']].min(axis=1)).all() で価格下限制約"
        - "df['close'].pct_change().abs() > 0.5 で異常変動率検出"
        - "df.index.to_series().diff() で時系列間隔を計算し、mode()*2 超のギャップ検出"
      implementation_hints:
        - "価格制約: max(axis=1)/min(axis=1) で行ごとの最大・最小を取得して比較"
        - "時系列ギャップ: mode() で最頻値を期待頻度とし、その2倍を閾値とする"
        - "dataframe_schemaでカラム存在・dtype・NaN・単調性は既にカバー済み"

  - id: check_aligned_data
    description: "Validate ML-ready data quality before model training"
    impl: "apps.algo_trade_pipeline.checks.feature_checks:check_aligned_data"
    file_path: "checks/feature_checks.py"
    input_type_ref: AlignedFeatureTarget
    spec_metadata:
      logic_steps:
        - "features.index.equals(target.index) でインデックス完全一致確認"
        - "len(features) == len(target) で行数一致チェック"
        - "features.isnull().any(axis=1).any() でNaN行検出"
        - "target.isnull().any(axis=1).any() でNaN行検出"
        - "np.isinf(features).any().any() および np.isinf(target).any().any() でInf検出"
        - "(features.nunique() == 1).sum() で定数列カウント（> 0 なら警告）"
        - "target.std().values[0] < 1e-6 でターゲット変数がほぼ定数か判定"
        - "(features.std() > 1000).any() で極端なスケールの列を検出"
      implementation_hints:
        - "2つのDataFrame間の整合性チェックが主目的"
        - "定数列: nunique() == 1 で全行が同じ値の列を検出"
        - "スケール検出: std() > 1000 は経験的閾値、データに応じて調整"
        - "type_aliasのみでdataframe_schema未定義のため全検証が必要"

  # Phase 3: Model Training & Prediction
  - id: check_cv_result
    description: "Validate cross-validation results and OOS predictions"
    impl: "apps.algo_trade_pipeline.checks.model_checks:check_cv_result"
    file_path: "checks/model_checks.py"
    input_type_ref: CVResult
    spec_metadata:
      logic_steps:
        - "len(cv_result.fold_results) > 0 でfold数が0でないことを確認"
        - "各fold.val_scoreに対して abs(score) < 100 で極端な値を検出"
        - "cv_result.oos_predictions.isnull().any().any() でNaN検出"
        - "np.isinf(cv_result.oos_predictions).any().any() でInf検出"
        - "len(cv_result.oos_predictions) > 0 で予測データが存在することを確認"
      implementation_hints:
        - "スコア閾値: abs(score) < 100 は回帰想定、分類なら0-1範囲にすべき"
        - "OOS予測: DataFrameはtype_aliasのためNaN/Inf検出が必要"
        - "Pydanticはリストの型のみカバー、要素内容はカスタムチェック必要"

  - id: check_prediction_data
    description: "Validate time-series prediction data consistency"
    impl: "apps.algo_trade_pipeline.checks.model_checks:check_prediction_data"
    file_path: "checks/model_checks.py"
    input_type_ref: PredictionDataList
    spec_metadata:
      logic_steps:
        - "df = pd.DataFrame([p.dict() for p in predictions]) でDataFrame化"
        - "pd.to_datetime(df['timestamp']).is_monotonic_increasing で時系列順序確認"
        - "df.groupby('timestamp')['symbol'].apply(lambda x: x.duplicated().any()).any() で重複検出"
        - "(df['prediction'] < 0).any() or (df['prediction'] > 1).any() で範囲外検出"
        - "(df['actual_return'] < -1).any() or (df['actual_return'] > 1).any() で異常値検出"
      implementation_hints:
        - "リストをDataFrame化すると集計・検証が効率的"
        - "groupby + apply で同一timestamp内の重複チェック"
        - "prediction範囲: 0-1はモデル依存、actual_return: -1～+1は±100%想定"
        - "Pydanticで範囲制約も可能だが現状未定義のためここでチェック"

  # Phase 4: Backtest & Evaluation
  - id: check_ranked_predictions
    description: "Validate ranking percentile distribution and uniqueness"
    impl: "apps.algo_trade_pipeline.checks.backtest_checks:check_ranked_predictions"
    file_path: "checks/backtest_checks.py"
    input_type_ref: RankedPredictionDataList
    spec_metadata:
      logic_steps:
        - "df = pd.DataFrame([r.dict() for r in ranked]) でDataFrame化"
        - "(df['prediction_rank_pct'] < 0).any() or (df['prediction_rank_pct'] > 1).any() で範囲外検出"
        - "df.groupby('timestamp')['prediction_rank_pct'].apply(lambda x: x.duplicated().any()).any() で重複検出"
      implementation_hints:
        - "rank_pct範囲: 0-1、Pydanticで定義可能だが未定義"
        - "同一timestamp内でrank_pctは一意であるべき"

  - id: check_selected_currencies_with_costs
    description: "Validate cost-adjusted returns are realistic"
    impl: "apps.algo_trade_pipeline.checks.backtest_checks:check_selected_currencies_with_costs"
    file_path: "checks/backtest_checks.py"
    input_type_ref: SelectedCurrencyDataWithCostsList
    spec_metadata:
      logic_steps:
        - "任意のdata.adjusted_returnに対して abs(data.adjusted_return) > 1.0 なら異常"
      implementation_hints:
        - "adjusted_return範囲: -1～+1（±100%想定）"
        - "リスト内包表記で全要素をチェック"

  - id: check_simulation_result
    description: "Validate portfolio simulation results and statistical distribution"
    impl: "apps.algo_trade_pipeline.checks.backtest_checks:check_simulation_result"
    file_path: "checks/backtest_checks.py"
    input_type_ref: SimulationResult
    spec_metadata:
      logic_steps:
        - "len(sim.portfolio_returns) > 0 で空でないことを確認"
        - "returns = pd.Series(sim.portfolio_returns) でSeries化"
        - "(returns < -1.0).any() or (returns > 10.0).any() で極端なリターン検出"
        - "returns.isnull().any() or np.isinf(returns).any() でNaN/Inf検出"
        - "from scipy import stats; abs(stats.skew(returns)) > 10 or abs(stats.kurtosis(returns)) > 20 で分布異常検出"
      implementation_hints:
        - "リターン範囲: -1（-100%）～+10（+1000%）は経験的閾値"
        - "歪度・尖度: scipy.statsを使用、極端な偏りを検出"
        - "Pydanticはリストの型のみカバー、要素内容は全てカスタムチェック"

  - id: check_performance_metrics
    description: "Validate performance metrics cross-field consistency"
    impl: "apps.algo_trade_pipeline.checks.backtest_checks:check_performance_metrics"
    file_path: "checks/backtest_checks.py"
    input_type_ref: PerformanceMetrics
    spec_metadata:
      logic_steps:
        - "metrics.max_drawdown > 0 なら異常（ドローダウンは負であるべき）"
        - "abs(metrics.sharpe_ratio) > 10 で非現実的な値を検出"
        - "metrics.calmar_ratioとmetrics.annual_return / abs(metrics.max_drawdown) の差が0.01超なら計算不整合"
        - "metrics.annual_volatility < 1e-6 でボラティリティがほぼ0なら異常"
      implementation_hints:
        - "Calmar ratio整合性: annual_return / abs(max_drawdown) と比較"
        - "Sharpe ratio: -10～10が現実的範囲"
        - "Pydanticで個別フィールド制約も可能だが、複数フィールド間関係はカスタムチェック必要"

examples:
  - id: ex_ingestion_config
    description: "Market data ingestion config example"
    datatype_ref: MarketDataIngestionConfig
    input:
      symbols: ["USDJPY", "EURUSD"]
      start_date: "2024-01-01"
      end_date: "2024-01-31"
      provider: "yahoo"
    expected:
      valid: true

  # - id: ex_ohlcv_row
  #   description: "OHLCV row example"
  #   datatype_ref: OHLCVRow
  #   input:
  #     timestamp: "2024-01-01T00:00:00"
  #     open: 145.50
  #     high: 146.00
  #     low: 145.00
  #     close: 145.80
  #     volume: 1000000
  #   expected:
  #     valid: true

  - id: ex_cv_config
    description: "CV configuration example"
    datatype_ref: SimpleCVConfig
    input:
      method: "TIME_SERIES"
      n_splits: 5
      test_size: 0.2
      gap: 0
    expected:
      valid: true

  - id: ex_prediction_data
    description: "Single prediction data example"
    datatype_ref: PredictionData
    input:
      timestamp: "2024-01-01T00:00:00"
      symbol: "USDJPY"
      prediction: 0.65
      actual_return: 0.02
    expected:
      valid: true

  - id: ex_performance_metrics
    description: "Performance metrics example"
    datatype_ref: PerformanceMetrics
    input:
      annual_return: 0.15
      annual_volatility: 0.12
      sharpe_ratio: 1.25
      max_drawdown: -0.08
      calmar_ratio: 1.875
    expected:
      valid: true

  - id: ex_fold_result
    description: "Fold result example"
    datatype_ref: FoldResult
    input:
      fold_index: 0
      train_score: 0.85
      val_score: 0.78
    expected:
      valid: true

  - id: ex_cv_method
    description: "CV method enum example"
    datatype_ref: CVMethod
    input: "TIME_SERIES"
    expected:
      valid: true

  - id: ex_position_signal
    description: "Position signal enum example"
    datatype_ref: PositionSignal
    input: 1
    expected:
      valid: true

  - id: ex_trading_cost_config
    description: "Trading cost configuration example"
    datatype_ref: TradingCostConfig
    input:
      swap_rates:
        USDJPY: 0.0001
        EURUSD: 0.0002
      spread_costs:
        USDJPY: 0.0003
        EURUSD: 0.0004
    expected:
      valid: true

  - id: ex_simple_lgbm_params
    description: "LightGBM parameters example"
    datatype_ref: SimpleLGBMParams
    input:
      learning_rate: 0.05
      num_leaves: 31
      max_depth: -1
    expected:
      valid: true

  - id: ex_selected_currency_data
    description: "Selected currency data example"
    datatype_ref: SelectedCurrencyData
    input:
      timestamp: "2024-01-01T00:00:00"
      symbol: "USDJPY"
      prediction: 0.65
      signal: 1
    expected:
      valid: true

  - id: ex_ranked_prediction_data
    description: "Ranked prediction data example"
    datatype_ref: RankedPredictionData
    input:
      timestamp: "2024-01-01T00:00:00"
      symbol: "USDJPY"
      prediction: 0.65
      actual_return: 0.02
      prediction_rank_pct: 0.85
    expected:
      valid: true

  - id: ex_selected_currency_with_costs
    description: "Selected currency with costs example"
    datatype_ref: SelectedCurrencyDataWithCosts
    input:
      timestamp: "2024-01-01T00:00:00"
      symbol: "USDJPY"
      prediction: 0.65
      signal: 1
      adjusted_return: 0.015
    expected:
      valid: true

  - id: ex_prediction_data_list
    description: "Prediction data list example"
    datatype_ref: PredictionDataList
    input:
      - timestamp: "2024-01-01T00:00:00"
        symbol: "USDJPY"
        prediction: 0.65
        actual_return: 0.02
      - timestamp: "2024-01-01T00:00:00"
        symbol: "EURUSD"
        prediction: 0.58
        actual_return: 0.01
    expected:
      valid: true

  - id: ex_ranked_prediction_data_list
    description: "Ranked prediction data list example"
    datatype_ref: RankedPredictionDataList
    input:
      - timestamp: "2024-01-01T00:00:00"
        symbol: "USDJPY"
        prediction: 0.65
        actual_return: 0.02
        prediction_rank_pct: 0.85
      - timestamp: "2024-01-01T00:00:00"
        symbol: "EURUSD"
        prediction: 0.58
        actual_return: 0.01
        prediction_rank_pct: 0.65
    expected:
      valid: true

  - id: ex_selected_currency_data_list
    description: "Selected currency data list example"
    datatype_ref: SelectedCurrencyDataList
    input:
      - timestamp: "2024-01-01T00:00:00"
        symbol: "USDJPY"
        prediction: 0.65
        signal: 1
      - timestamp: "2024-01-01T00:00:00"
        symbol: "EURUSD"
        prediction: 0.58
        signal: 1
    expected:
      valid: true

  - id: ex_selected_currency_with_costs_list
    description: "Selected currency with costs list example"
    datatype_ref: SelectedCurrencyDataWithCostsList
    input:
      - timestamp: "2024-01-01T00:00:00"
        symbol: "USDJPY"
        prediction: 0.65
        signal: 1
        adjusted_return: 0.015
      - timestamp: "2024-01-01T00:00:00"
        symbol: "EURUSD"
        prediction: 0.58
        signal: 1
        adjusted_return: 0.008
    expected:
      valid: true

generators:
  - id: gen_provider_batches
    description: "Synthesize provider batch payloads"
    impl: "apps.algo_trade_pipeline.generators.market_data:generate_provider_batches"
    file_path: "generators/market_data.py"
    return_type_ref: ProviderBatchCollection
    spec_metadata:
      logic_steps:
        - "複数のプロバイダを想定したダミーDataFrameを生成"
        - "各DataFrameにはOHLCV形式のデータを含める"
        - "プロバイダごとに微妙に異なる列名やフォーマットを持たせる（正規化前を想定）"
        - "ProviderBatchCollectionオブジェクトにbatchesリストとして格納"
      implementation_hints:
        - "pandasとnumpyで合成データを生成"
        - "テストデータとして現実的な価格範囲を保持"
        - "2-3個のバッチを生成してマルチプロバイダを模擬"

  - id: gen_normalized_bundle
    description: "Create a normalized OHLCV bundle"
    impl: "apps.algo_trade_pipeline.generators.market_data:generate_normalized_bundle"
    file_path: "generators/market_data.py"
    return_type_ref: NormalizedOHLCVBundle
    spec_metadata:
      logic_steps:
        - "正規化済みのMultiAssetOHLCVFrameを生成"
        - "標準OHLCV列名（open, high, low, close, volume）を持つ"
        - "タイムスタンプインデックス、UTC形式で統一"
        - "NormalizedOHLCVBundleオブジェクトにdataとして格納"
      implementation_hints:
        - "gen_multiasset_frameを内部で呼び出すか、同様のロジックを使用"
        - "テストデータとして価格制約を満たす現実的な値を生成"

  - id: gen_multiasset_frame
    description: "Build a sample multi-asset OHLCV frame"
    impl: "apps.algo_trade_pipeline.generators.market_data:generate_multiasset_frame"
    file_path: "generators/market_data.py"
    return_type_ref: MultiAssetOHLCVFrame
    spec_metadata:
      logic_steps:
        - "複数シンボル（例: USDJPY, EURUSD）のOHLCVデータを生成"
        - "MultiIndex構造（第1レベル=symbol、第2レベル=OHLCV列）を構築"
        - "タイムスタンプインデックスで全シンボルを統一"
        - "価格制約（high >= max(open, close)、low <= min(open, close)）を満たす"
      implementation_hints:
        - "pd.concat()でaxis=1方向に結合し、keys引数でシンボルを指定"
        - "各シンボルごとに個別にOHLCVを生成してから結合"
        - "テストデータとして2-3シンボル、50-100行程度を推奨"

  - id: gen_snapshot_meta
    description: "Produce snapshot metadata for persisted market data"
    impl: "apps.algo_trade_pipeline.generators.market_data:generate_snapshot_meta"
    file_path: "generators/market_data.py"
    return_type_ref: MarketDataSnapshotMeta
    spec_metadata:
      logic_steps:
        - "一意なスナップショットIDを生成（UUID推奨）"
        - "現在のタイムスタンプをISO 8601形式で取得"
        - "サンプルシンボルリスト（例: ['USDJPY', 'EURUSD']）を定義"
        - "MarketDataSnapshotMetaオブジェクトを構築"
      implementation_hints:
        - "import uuid; snapshot_id = str(uuid.uuid4())"
        - "datetime.utcnow().isoformat() でタイムスタンプ生成"
        - "テストデータとして固定値または動的生成を選択"

  - id: gen_ohlcv_frame
    description: "Generate a resampled OHLCV frame"
    impl: "apps.algo_trade_pipeline.generators.feature_engineering:generate_ohlcv_frame"
    file_path: "generators/feature_engineering.py"
    return_type_ref: OHLCVFrame
    spec_metadata:
      logic_steps:
        - "1時間頻度でdatetimeインデックスを作成"
        - "価格制約を満たす現実的なOHLCV値を生成"
        - "high >= max(open, close) かつ low <= min(open, close) を保証"
        - "オプションでランダムな整数値のvolume列を追加"
      implementation_hints:
        - "pandasとnumpyを使用して効率的にデータ生成"
        - "テストデータの現実性のため価格制約を維持する必要がある"

  - id: gen_feature_frame
    description: "Assemble a feature DataFrame"
    impl: "apps.algo_trade_pipeline.generators.feature_engineering:generate_feature_frame"
    file_path: "generators/feature_engineering.py"
    return_type_ref: FeatureFrame
    spec_metadata:
      logic_steps:
        - "OHLCV列に加えて、複数のテクニカル指標列を含むDataFrameを生成"
        - "例: rsi_14, adx_14, recent_return_5, volatility_20 などの特徴量列"
        - "タイムスタンプインデックスで統一"
        - "NaN値は初期期間のみに限定"
      implementation_hints:
        - "gen_ohlcv_frameで基本データを生成後、手動で特徴量列を追加"
        - "特徴量値はランダム生成でも可（テスト目的）"
        - "現実的な値の範囲を保持（RSI: 0-100、リターン: -0.1～0.1等）"

  - id: gen_target_frame
    description: "Assemble a target DataFrame"
    impl: "apps.algo_trade_pipeline.generators.feature_engineering:generate_target_frame"
    file_path: "generators/feature_engineering.py"
    return_type_ref: TargetFrame
    spec_metadata:
      logic_steps:
        - "単一のtarget列を持つDataFrameを生成"
        - "将来リターンを模擬した値（例: -0.05～0.05のランダム値）"
        - "タイムスタンプインデックスで統一"
      implementation_hints:
        - "np.random.uniform(-0.05, 0.05, size=len(index)) でランダム生成"
        - "またはgen_ohlcv_frameのclose価格から将来リターンを計算"
        - "テストデータとして現実的なリターン分布を保持"

  - id: gen_aligned_feature_target
    description: "Align feature and target frames"
    impl: "apps.algo_trade_pipeline.generators.feature_engineering:generate_aligned_feature_target"
    file_path: "generators/feature_engineering.py"
    return_type_ref: AlignedFeatureTarget
    spec_metadata:
      logic_steps:
        - "gen_feature_frameとgen_target_frameを呼び出してそれぞれ生成"
        - "共通のタイムスタンプインデックスを持つように調整"
        - "NaN行を除去してクリーンなデータセットを作成"
        - "タプル (features, target) として返却"
      implementation_hints:
        - "同じインデックスを共有するように生成時に調整"
        - "dropna()で両方のDataFrameをクリーニング"
        - "テストデータとして30-50行程度を推奨"

  - id: gen_cv_result
    description: "Create a minimal CV result payload"
    impl: "apps.algo_trade_pipeline.generators.model:generate_cv_result"
    file_path: "generators/model.py"
    return_type_ref: CVResult
    spec_metadata:
      logic_steps:
        - "各foldに対してランダムスコアを持つFoldResultを生成"
        - "タイムスタンプと予測値を含むOOS予測DataFrameを作成"
        - "すべての結果をCVResult構造に統合"
      implementation_hints:
        - "テスト用に合成クロスバリデーション結果を生成"
        - "pandasでDataFrame作成、numpyでランダム値生成を行う"

  - id: gen_simulation_result
    description: "Create a simulation result payload"
    impl: "apps.algo_trade_pipeline.generators.backtest:generate_simulation_result"
    file_path: "generators/backtest.py"
    return_type_ref: SimulationResult
    spec_metadata:
      logic_steps:
        - "ポートフォリオリターンのリストを生成（例: 50-100期間分）"
        - "リターン値は現実的な範囲（-0.05～0.05程度）でランダム生成"
        - "equity_curve = (1 + returns).cumprod() で累積リターンを計算"
        - "SimulationResultオブジェクトにportfolio_returnsとequity_curveを格納"
      implementation_hints:
        - "np.random.normal(0.001, 0.02, size=100) でリターンを正規分布生成"
        - "equity_curveはpd.Series型でタイムスタンプインデックス付き"
        - "テストデータとして現実的なリターン分布を保持"

datatypes:
  # ===== Phase 1: Market Data Ingestion =====
  - id: MarketDataIngestionConfig
    description: "Configuration for market data ingestion (symbols, date range, provider)"
    examples:
      - symbols: ["USDJPY", "EURUSD"]
        start_date: "2024-01-01"
        end_date: "2024-01-31"
        provider: "yahoo"
    pydantic_model:
      fields:
        - name: symbols
          type:
            generic:
              container: list
              element_type:
                native: "builtins:str"
          description: "List of trading symbols"
        - name: start_date
          type:
            native: "builtins:str"
          description: "Start date (YYYY-MM-DD)"
        - name: end_date
          type:
            native: "builtins:str"
          description: "End date (YYYY-MM-DD)"
        - name: provider
          type:
            native: "builtins:str"
          description: "Data provider name"

  - id: ProviderBatchCollection
    description: "Collection of raw data batches from multiple providers"
    pydantic_model:
      fields:
        - name: batches
          type:
            generic:
              container: list
              element_type:
                native: "pandas:DataFrame"
          description: "Raw OHLCV DataFrames from providers"

  - id: NormalizedOHLCVBundle
    description: "Normalized OHLCV data bundle from multiple providers"
    pydantic_model:
      fields:
        - name: data
          type:
            datatype_ref: MultiAssetOHLCVFrame
          description: "Normalized OHLCV data as MultiAsset DataFrame"

  # Using type_alias for MultiIndex DataFrame
  - id: MultiAssetOHLCVFrame
    description: "Multi-asset OHLCV DataFrame with MultiIndex structure (symbol, column)"
    check_functions:
      - check_multiasset_frame
    type_alias:
      type: simple
      target: "pandas:DataFrame"

  - id: MarketDataSnapshotMeta
    description: "Metadata for persisted market data snapshot"
    pydantic_model:
      fields:
        - name: snapshot_id
          type:
            native: "builtins:str"
          description: "Unique snapshot identifier"
        - name: timestamp
          type:
            native: "builtins:str"
          description: "Snapshot timestamp (ISO 8601)"
        - name: symbols
          type:
            generic:
              container: list
              element_type:
                native: "builtins:str"
          description: "List of included symbols"

  # # OHLCVRow: 単一行データの構造定義（exampleバリデーション用）
  # - id: OHLCVRow
  #   description: "Single OHLCV row data structure for validation"
  #   examples:
  #     - timestamp: "2024-01-01T00:00:00"
  #       open: 145.50
  #       high: 146.00
  #       low: 145.00
  #       close: 145.80
  #       volume: 1000000
  #   pydantic_model:
  #     fields:
  #       - name: timestamp
  #         type:
  #           native: "datetime:datetime"
  #         description: "Timestamp (index)"
  #       - name: open
  #         type:
  #           native: "builtins:float"
  #         description: "Open price"
  #       - name: high
  #         type:
  #           native: "builtins:float"
  #         description: "High price"
  #       - name: low
  #         type:
  #           native: "builtins:float"
  #         description: "Low price"
  #       - name: close
  #         type:
  #           native: "builtins:float"
  #         description: "Close price"
  #       - name: volume
  #         type:
  #           native: "builtins:int"
  #         optional: true
  #         description: "Volume"

  # ===== Phase 2: Feature Engineering =====
  - id: OHLCVFrame
    description: "OHLCV DataFrame"
    check_functions:
      - check_ohlcv
    type_alias:
      type: simple
      target: "pandas:DataFrame"
    dataframe_schema:
      index:
        name: timestamp
        dtype: datetime
        nullable: false
        unique: false
        monotonic: ""
        description: "Timestamp index"
      columns:
        - name: open
          dtype: float
          nullable: false
          description: "Open price"
        - name: high
          dtype: float
          nullable: false
          description: "High price"
        - name: low
          dtype: float
          nullable: false
          checks:
            - type: ge
              value: 0
              description: "Low price must be non-negative"
          description: "Low price"
        - name: close
          dtype: float
          nullable: false
          description: "Close price"
        - name: volume
          dtype: int
          nullable: true
          description: "Trading volume"
      strict: false
      coerce: true
      ordered: false
    schema:
      type: array
      items:
        type: object
        properties:
          timestamp:
            type: string
            format: date-time
          open:
            type: number
          high:
            type: number
          low:
            type: number
          close:
            type: number
          volume:
            type: integer
        required:
          - timestamp
          - open
          - high
          - low
          - close

  - id: FeatureFrame
    description: "Feature DataFrame (flattened from MultiIndex)"
    type_alias:
      type: simple
      target: "pandas:DataFrame"

  - id: TargetFrame
    description: "Target variable DataFrame (single column)"
    type_alias:
      type: simple
      target: "pandas:DataFrame"

  # Using type_alias with tuple for aligned data
  - id: AlignedFeatureTarget
    description: "Aligned feature and target DataFrames (cleaned, index-matched)"
    check_functions:
      - check_aligned_data
    type_alias:
      type: tuple
      elements:
        - datatype_ref: FeatureFrame
        - datatype_ref: TargetFrame

  # ===== Phase 3: Model Training & Prediction =====
  - id: CVMethod
    description: "Cross-validation method types"
    enum:
      base_type: str
      members:
        - name: TIME_SERIES
          value: "TIME_SERIES"
          description: "Time-series CV split"
        - name: EXPANDING_WINDOW
          value: "EXPANDING_WINDOW"
          description: "Expanding window split"
        - name: SLIDING_WINDOW
          value: "SLIDING_WINDOW"
          description: "Sliding window split"

  - id: SimpleCVConfig
    description: "Cross-validation configuration (method, splits, test_size, gap)"
    examples:
      - method: "TIME_SERIES"
        n_splits: 5
        test_size: 0.2
        gap: 0
    pydantic_model:
      fields:
        - name: method
          type:
            datatype_ref: CVMethod
          description: "CV splitting method"
        - name: n_splits
          type:
            native: "builtins:int"
          description: "Number of CV splits"
        - name: test_size
          type:
            native: "builtins:float"
          optional: true
          description: "Test set size ratio"
        - name: gap
          type:
            native: "builtins:int"
          default: 0
          description: "Gap between train and test"

  # Using generic for dict
  - id: SimpleLGBMParams
    description: "LightGBM hyperparameters dictionary"
    generic:
      container: dict
      key_type:
        native: "builtins:str"
      value_type:
        native: "typing:Any"

  - id: FoldResult
    description: "Single fold training result with metrics"
    pydantic_model:
      fields:
        - name: fold_index
          type:
            native: "builtins:int"
          description: "Fold index (0-based)"
        - name: train_score
          type:
            native: "builtins:float"
          optional: true
          description: "Training score for this fold"
        - name: val_score
          type:
            native: "builtins:float"
          optional: true
          description: "Validation score for this fold"

  - id: CVResult
    description: "Cross-validation training result (models, metrics, OOS predictions)"
    check_functions:
      - check_cv_result
    pydantic_model:
      fields:
        - name: fold_results
          type:
            generic:
              container: list
              element_type:
                datatype_ref: FoldResult
          description: "Results from each fold"
        - name: oos_predictions
          type:
            native: "pandas:DataFrame"
          optional: true
          description: "Out-of-sample predictions"

  - id: PredictionData
    description: "Single prediction data point (timestamp, symbol, prediction, actual)"
    examples:
      - timestamp: "2024-01-01T00:00:00"
        symbol: "USDJPY"
        prediction: 0.65
        actual_return: 0.02
    pydantic_model:
      fields:
        - name: timestamp
          type:
            native: "builtins:str"
          description: "Prediction timestamp"
        - name: symbol
          type:
            native: "builtins:str"
          description: "Trading symbol"
        - name: prediction
          type:
            native: "builtins:float"
          description: "Predicted value"
        - name: actual_return
          type:
            native: "builtins:float"
          optional: true
          description: "Actual return (for evaluation)"

  # Using generic for list
  - id: PredictionDataList
    description: "List of prediction data points"
    generic:
      container: list
      element_type:
        datatype_ref: PredictionData

  # ===== Phase 4: Backtest & Evaluation =====
  - id: RankedPredictionData
    description: "Prediction data with ranking percentile"
    pydantic_model:
      fields:
        - name: timestamp
          type:
            native: "builtins:str"
        - name: symbol
          type:
            native: "builtins:str"
        - name: prediction
          type:
            native: "builtins:float"
        - name: actual_return
          type:
            native: "builtins:float"
          optional: true
        - name: prediction_rank_pct
          type:
            native: "builtins:float"
          description: "Prediction rank percentile (0-1)"

  - id: RankedPredictionDataList
    description: "List of ranked prediction data"
    generic:
      container: list
      element_type:
        datatype_ref: RankedPredictionData

  # Using enum for PositionSignal
  - id: PositionSignal
    description: "Trading position signal"
    enum:
      base_type: int
      members:
        - name: BUY
          value: 1
          description: "Long position"
        - name: SELL
          value: -1
          description: "Short position"
        - name: HOLD
          value: 0
          description: "No position"

  - id: SelectedCurrencyData
    description: "Selected currency with position signal (BUY/SELL/HOLD)"
    pydantic_model:
      fields:
        - name: timestamp
          type:
            native: "builtins:str"
        - name: symbol
          type:
            native: "builtins:str"
        - name: prediction
          type:
            native: "builtins:float"
        - name: signal
          type:
            datatype_ref: PositionSignal
          description: "Position signal"

  - id: SelectedCurrencyDataList
    description: "List of selected currency data"
    generic:
      container: list
      element_type:
        datatype_ref: SelectedCurrencyData

  - id: TradingCostConfig
    description: "Trading cost configuration (swap rates, spreads)"
    pydantic_model:
      fields:
        - name: swap_rates
          type:
            generic:
              container: dict
              key_type:
                native: "builtins:str"
              value_type:
                native: "builtins:float"
          description: "Swap rates per symbol"
        - name: spread_costs
          type:
            generic:
              container: dict
              key_type:
                native: "builtins:str"
              value_type:
                native: "builtins:float"
          description: "Spread costs per symbol"

  - id: SelectedCurrencyDataWithCosts
    description: "Selected currency data with adjusted returns (swap & spread)"
    pydantic_model:
      fields:
        - name: timestamp
          type:
            native: "builtins:str"
        - name: symbol
          type:
            native: "builtins:str"
        - name: prediction
          type:
            native: "builtins:float"
        - name: signal
          type:
            datatype_ref: PositionSignal
        - name: adjusted_return
          type:
            native: "builtins:float"
          description: "Return adjusted for swap and spread"

  - id: SelectedCurrencyDataWithCostsList
    description: "List of selected currency data with costs"
    generic:
      container: list
      element_type:
        datatype_ref: SelectedCurrencyDataWithCosts

  - id: SimulationResult
    description: "Portfolio simulation result (returns, positions, equity curve)"
    pydantic_model:
      fields:
        - name: portfolio_returns
          type:
            generic:
              container: list
              element_type:
                native: "builtins:float"
          description: "Time series of portfolio returns"
        - name: equity_curve
          type:
            native: "pandas:Series"
          optional: true
          description: "Portfolio equity curve"

  - id: PerformanceMetrics
    description: "Performance metrics (annual return, Sharpe, max drawdown, etc.)"
    examples:
      - annual_return: 0.15
        annual_volatility: 0.12
        sharpe_ratio: 1.25
        max_drawdown: -0.08
        calmar_ratio: 1.875
    pydantic_model:
      fields:
        - name: annual_return
          type:
            native: "builtins:float"
          description: "Annualized return"
        - name: annual_volatility
          type:
            native: "builtins:float"
          optional: true
          description: "Annualized volatility"
        - name: sharpe_ratio
          type:
            native: "builtins:float"
          description: "Sharpe ratio"
        - name: max_drawdown
          type:
            native: "builtins:float"
          description: "Maximum drawdown"
        - name: calmar_ratio
          type:
            native: "builtins:float"
          optional: true
          description: "Calmar ratio"

transforms:
  # ===== Phase 1: Market Data Ingestion =====
  - id: fetch_yahoo_finance_ohlcv
    description: "Fetch OHLCV data from Yahoo Finance API"
    impl: "apps.algo_trade_pipeline.transforms.market_data:fetch_yahoo_finance_ohlcv"
    file_path: "transforms/market_data.py"
    parameters:
      - name: config
        datatype_ref: MarketDataIngestionConfig
    return_type_ref: ProviderBatchCollection
    spec_metadata:
      logic_steps:
        - "設定から取得対象のシンボルリスト、開始日、終了日、プロバイダ名を抽出"
        - "Yahoo Finance APIに接続して各シンボルのOHLCVデータをリクエスト"
        - "APIレスポンスをDataFrame形式でパース"
        - "取得した全DataFrameをProviderBatchCollectionとして集約して返却"
      implementation_hints:
        - "yfinanceライブラリまたはpandas_datareaderを使用してAPIアクセス"
        - "APIエラー（ネットワーク、レート制限、シンボル不正）はyfinanceの例外をそのまま伝播"
        - "プロバイダ名はyahoo固定だが将来の拡張性のために設定として保持"
      explicit_checks:
        - "symbols リストが空でないことを確認 → ValueError('Empty symbols list')"
        - "start_date < end_date を確認 → ValueError('Invalid date range: start_date must be before end_date')"

  - id: normalize_multi_provider
    description: "Normalize data from multiple providers to unified format"
    impl: "apps.algo_trade_pipeline.transforms.market_data:normalize_multi_provider"
    file_path: "transforms/market_data.py"
    parameters:
      - name: batches
        datatype_ref: ProviderBatchCollection
    return_type_ref: NormalizedOHLCVBundle
    spec_metadata:
      logic_steps:
        - "各プロバイダバッチからDataFrameを抽出"
        - "プロバイダ固有の列名を標準OHLCV形式（open, high, low, close, volume）にマッピング"
        - "全タイムスタンプをUTC datetime形式に変換（pd.to_datetime().tz_localize('UTC')）"
        - "データの完全性を検証し、OHLC値が欠損している行を削除"
        - "正規化された全DataFrameを単一結果に結合（pd.concat()）"
      implementation_hints:
        - "pandasでDataFrame操作、datetimeでタイムスタンプ変換を行う"
        - "プロバイダ固有の列マッピングは設定ファイルまたはルックアップテーブルが必要な可能性"
        - "UTC変換によりプロバイダ間のタイムゾーン一貫性を確保"

  - id: merge_market_data_bundle
    description: "Merge normalized bundle into MultiIndex DataFrame"
    impl: "apps.algo_trade_pipeline.transforms.market_data:merge_market_data_bundle"
    file_path: "transforms/market_data.py"
    parameters:
      - name: bundle
        datatype_ref: NormalizedOHLCVBundle
    return_type_ref: MultiAssetOHLCVFrame
    spec_metadata:
      logic_steps:
        - "NormalizedOHLCVBundleからMultiAssetOHLCVFrameを抽出"
        - "各シンボルごとにOHLCV列を保持したままMultiIndexを構築"
        - "第1レベルをシンボル名、第2レベルをOHLCV列名とするMultiIndex構造を作成"
        - "全シンボルのデータを単一のDataFrameに統合"
      implementation_hints:
        - "pd.concat()でaxis=1方向に結合し、keys引数でシンボル名を指定"
        - "結果のdf.columnsがMultiIndex (symbol, ohlcv_column) になることを確認"
        - "インデックスはタイムスタンプで共通化され、欠損は適切に処理"

  - id: persist_market_data_snapshot
    description: "Persist market data to storage and return metadata"
    impl: "apps.algo_trade_pipeline.transforms.market_data:persist_market_data_snapshot"
    file_path: "transforms/market_data.py"
    parameters:
      - name: frame
        datatype_ref: MultiAssetOHLCVFrame
      - name: config
        datatype_ref: MarketDataIngestionConfig
    return_type_ref: MarketDataSnapshotMeta
    spec_metadata:
      logic_steps:
        - "一意なスナップショットIDを生成（UUID、タイムスタンプベースなど）"
        - "MultiAssetOHLCVFrameをストレージに永続化（Parquet, CSV, HDF5等）"
        - "保存したファイルパス、タイムスタンプ、シンボルリストをメタデータとして記録"
        - "MarketDataSnapshotMetaオブジェクトを構築して返却"
      implementation_hints:
        - "Parquet形式が推奨（圧縮効率、MultiIndex対応、高速読み込み）"
        - "output/data/market_snapshots/ ディレクトリに保存"
        - "スナップショットIDはファイル名に含めて後から参照可能にする"
        - "メタデータは別途JSON等で保存しても良い"

  # ===== Phase 2: Feature Engineering =====
  - id: resample_ohlcv
    description: "Resample OHLCV data to specified frequency (e.g., 1h, 4h, 1D)"
    impl: "apps.algo_trade_pipeline.transforms.features:resample_ohlcv"
    file_path: "transforms/features.py"
    parameters:
      - name: df
        datatype_ref: MultiAssetOHLCVFrame
      - name: freq
        native: "builtins:str"
        default: "1h"
    return_type_ref: OHLCVFrame
    spec_metadata:
      logic_steps:
        - "MultiAssetOHLCVFrameから単一シンボルまたは代表シンボルを選択"
        - "pandas resample()を使用して指定周期（freq）にリサンプル"
        - "OHLCV各カラムに適切な集約関数を適用（open:first, high:max, low:min, close:last, volume:sum）"
        - "リサンプル結果をOHLCVFrame形式で返却"
      implementation_hints:
        - "df.resample(freq)を使用、タイムスタンプインデックス必須"
        - "MultiIndexの場合は最初のシンボルを抽出、または全シンボルを平均化"
        - "freq文字列はpandas頻度コード（'1h', '4h', '1D'等）を想定"
        - "欠損期間の処理方針（forward fill, drop等）を決定"

  - id: calculate_rsi
    description: "Calculate RSI indicator and add rsi_{period} column"
    impl: "apps.algo_trade_pipeline.transforms.features:calculate_rsi"
    file_path: "transforms/features.py"
    parameters:
      - name: df
        datatype_ref: OHLCVFrame
      - name: period
        native: "builtins:int"
        default: 14
    return_type_ref: FeatureFrame
    spec_metadata:
      logic_steps:
        - "close価格の前日比変化を計算"
        - "上昇変化量（gain）と下落変化量（loss）を分離"
        - "指定期間でgainとlossの移動平均を計算"
        - "RS（Relative Strength）= 平均gain / 平均lossを算出"
        - "RSI = 100 - (100 / (1 + RS)) で最終指標を計算"
        - "rsi_{period}列としてDataFrameに追加"
      implementation_hints:
        - "RSI計算はテクニカル分析ライブラリ（ta, ta-lib等）の使用も可"
        - "移動平均はSMA（単純移動平均）またはEMA（指数移動平均）を選択"
        - "period期間分の初期NaNが発生するため、後続処理で考慮"
        - "RSI値は0-100の範囲で、70以上が買われすぎ、30以下が売られすぎ"

  - id: calculate_adx
    description: "Calculate ADX indicator and add adx_{period} column"
    impl: "apps.algo_trade_pipeline.transforms.features:calculate_adx"
    file_path: "transforms/features.py"
    parameters:
      - name: df
        datatype_ref: OHLCVFrame
      - name: period
        native: "builtins:int"
        default: 14
    return_type_ref: FeatureFrame
    spec_metadata:
      logic_steps:
        - "+DM（Positive Directional Movement）と-DM（Negative Directional Movement）を計算"
        - "TR（True Range）を計算"
        - "+DI（Positive Directional Indicator）と-DI（Negative Directional Indicator）を算出"
        - "DX（Directional Movement Index）= |+DI - -DI| / (+DI + -DI) * 100を計算"
        - "DXの移動平均を取ってADXを算出"
        - "adx_{period}列としてDataFrameに追加"
      implementation_hints:
        - "ADX計算はテクニカル分析ライブラリ（ta, ta-lib等）の使用を推奨"
        - "high, low, close価格が必要"
        - "ADX値は0-100の範囲で、25以上がトレンド有り、20以下がトレンド無し"
        - "period期間分の初期NaNが発生"

  - id: calculate_recent_return
    description: "Calculate recent return and add recent_return_{lookback} column"
    impl: "apps.algo_trade_pipeline.transforms.features:calculate_recent_return"
    file_path: "transforms/features.py"
    parameters:
      - name: df
        datatype_ref: OHLCVFrame
      - name: lookback
        native: "builtins:int"
        default: 5
    return_type_ref: FeatureFrame
    spec_metadata:
      logic_steps:
        - "close価格のlookback期間前との比較でリターンを計算"
        - "(close - close.shift(lookback)) / close.shift(lookback) でパーセンテージリターンを算出"
        - "recent_return_{lookback}列としてDataFrameに追加"
      implementation_hints:
        - "pandasのpct_change(periods=lookback)を使用すると簡潔"
        - "lookback期間分の初期NaNが発生"
        - "リターン値は-1～+1程度の範囲（-100%～+100%）"

  - id: calculate_volatility
    description: "Calculate volatility and add volatility_{window} column"
    impl: "apps.algo_trade_pipeline.transforms.features:calculate_volatility"
    file_path: "transforms/features.py"
    parameters:
      - name: df
        datatype_ref: OHLCVFrame
      - name: window
        native: "builtins:int"
        default: 20
    return_type_ref: FeatureFrame
    spec_metadata:
      logic_steps:
        - "close価格の前日比リターンを計算"
        - "リターンの標準偏差をwindow期間で移動計算"
        - "volatility_{window}列としてDataFrameに追加"
      implementation_hints:
        - "df['close'].pct_change().rolling(window).std() で計算"
        - "年率換算する場合は sqrt(252) や sqrt(365*24) を乗算（時間単位による）"
        - "window期間分の初期NaNが発生"
        - "ボラティリティは価格変動の大きさを示す指標"

  - id: calculate_future_return
    description: "Calculate future return as target variable (add target column)"
    impl: "apps.algo_trade_pipeline.transforms.features:calculate_future_return"
    file_path: "transforms/features.py"
    parameters:
      - name: df
        datatype_ref: FeatureFrame
      - name: forward
        native: "builtins:int"
        default: 5
      - name: convert_type
        native: "builtins:str"
        literal:
          - "RETURN"
          - "DIRECTION"
          - "LOG_RETURN"
        default: "RETURN"
    return_type_ref: TargetFrame
    spec_metadata:
      logic_steps:
        - "close価格のforward期間後との比較で将来リターンを計算"
        - "convert_type='RETURN': (close.shift(-forward) - close) / close"
        - "convert_type='DIRECTION': future_returnの符号（+1, 0, -1）"
        - "convert_type='LOG_RETURN': log(close.shift(-forward) / close)"
        - "target列としてDataFrameに追加"
      implementation_hints:
        - "shift(-forward)で未来の値を参照するため末尾forward行はNaN"
        - "DIRECTION変換はnp.sign()を使用して3クラス分類問題に"
        - "LOG_RETURNは対称性が高くモデル学習に有利な場合あり"
        - "予測対象はforward期間後のリターンであることに注意"

  - id: clean_and_align_feature_target
    description: "Clean and align feature and target frames to ensure matching indexes"
    impl: "apps.algo_trade_pipeline.transforms.features:clean_and_align_feature_target"
    file_path: "transforms/features.py"
    parameters:
      - name: target
        datatype_ref: TargetFrame
      - name: features
        datatype_ref: FeatureFrame
    return_type_ref: AlignedFeatureTarget
    spec_metadata:
      logic_steps:
        - "featuresとtargetの共通インデックスを取得"
        - "NaN値を含む行を両方のDataFrameから除去"
        - "インデックスを完全一致させる（inner join相当）"
        - "タプル (features, target) として返却"
      implementation_hints:
        - "pd.DataFrame.dropna()でNaN行を除去"
        - "共通インデックス: features.index.intersection(target.index)"
        - "または pd.concat([features, target], axis=1, join='inner').dropna()"
        - "最終的にlen(features) == len(target)かつindex完全一致を保証"

  # ===== Phase 3: Model Training & Prediction =====
  - id: train_lightgbm_cv
    description: "Train LightGBM with cross-validation (internal CV split generation)"
    impl: "apps.algo_trade_pipeline.transforms.model:train_lightgbm_cv"
    file_path: "transforms/model.py"
    parameters:
      - name: aligned_data
        datatype_ref: AlignedFeatureTarget
      - name: cv_config
        datatype_ref: SimpleCVConfig
        optional: true
      - name: lgbm_params
        datatype_ref: SimpleLGBMParams
        optional: true
    return_type_ref: CVResult
    spec_metadata:
      logic_steps:
        - "タプルからアラインされた特徴量とターゲットDataFrameをアンパック"
        - "cv_configを使用して選択された方法（TIME_SERIES, EXPANDING_WINDOW, SLIDING_WINDOW）に従って訓練/テスト分割を生成"
        - "各foldごとに: 訓練/検証インデックスを抽出しLightGBMデータセットを作成"
        - "各foldでlgbm_paramsを使ってLightGBMモデルを訓練"
        - "各foldの検証予測とメトリクス（train_score, val_score）を計算"
        - "全fold結果を収集し、OOS予測を単一DataFrameに連結"
        - "fold_resultsリストとoos_predictions DataFrameを含むCVResultを返却"
      implementation_hints:
        - "時系列CVは時間順序を尊重することでデータリークを防ぐ"
        - "OOS予測は偏りのない性能推定に不可欠"
        - "デフォルトのcv_configは未提供の場合5-fold時系列分割を使用"
        - "lightgbm、pandas、numpyをモデル訓練とデータ処理に使用"

  - id: generate_predictions
    description: "Generate prediction data list from CV OOS predictions"
    impl: "apps.algo_trade_pipeline.transforms.model:generate_predictions"
    file_path: "transforms/model.py"
    parameters:
      - name: cv_result
        datatype_ref: CVResult
      - name: aligned_data
        datatype_ref: AlignedFeatureTarget
    return_type_ref: PredictionDataList
    spec_metadata:
      logic_steps:
        - "cv_resultからOOS予測DataFrameを抽出"
        - "aligned_dataから実際のターゲット値（actual_return）を取得"
        - "各行をPredictionDataオブジェクトに変換（timestamp, symbol, prediction, actual_return）"
        - "PredictionDataListとして返却"
      implementation_hints:
        - "OOS予測DataFrameとターゲットをインデックスで結合"
        - "symbolはマルチシンボル対応の場合は別途管理が必要"
        - "timestamp列がインデックスの場合はreset_index()で取得"
        - "リスト内包表記でPydanticモデルを効率的に生成"

  # ===== Phase 4: Backtest & Evaluation =====
  - id: rank_predictions
    description: "Rank predictions and add prediction_rank_pct column"
    impl: "apps.algo_trade_pipeline.transforms.backtest:rank_predictions"
    file_path: "transforms/backtest.py"
    parameters:
      - name: predictions
        datatype_ref: PredictionDataList
    return_type_ref: RankedPredictionDataList
    spec_metadata:
      logic_steps:
        - "PredictionDataListをDataFrameに変換"
        - "各タイムスタンプ内で予測値（prediction）をランク付け"
        - "ランクをパーセンタイル（0-1）に変換してprediction_rank_pct列を追加"
        - "RankedPredictionDataListとして返却"
      implementation_hints:
        - "df.groupby('timestamp')['prediction'].rank(pct=True) でパーセンタイル計算"
        - "pct=Trueで0-1範囲の値を取得"
        - "高い予測値ほど高いパーセンタイル（1に近い）を持つ"
        - "リスト内包表記でRankedPredictionDataモデルに変換"

  - id: filter_top_predictions
    description: "Filter top N predictions and assign position signals"
    impl: "apps.algo_trade_pipeline.transforms.backtest:filter_top_predictions"
    file_path: "transforms/backtest.py"
    parameters:
      - name: ranked
        datatype_ref: RankedPredictionDataList
      - name: top_n
        native: "builtins:int"
        default: 3
      - name: threshold
        native: "builtins:float"
        default: 0.7
    return_type_ref: SelectedCurrencyDataList
    spec_metadata:
      logic_steps:
        - "RankedPredictionDataListをDataFrameに変換"
        - "各タイムスタンプごとにprediction_rank_pctが上位top_n件を抽出"
        - "prediction_rank_pct >= threshold の条件でさらにフィルタリング"
        - "選択された通貨にポジションシグナル（BUY=1）を割り当て"
        - "SelectedCurrencyDataListとして返却"
      implementation_hints:
        - "df.groupby('timestamp').apply(lambda x: x.nlargest(top_n, 'prediction_rank_pct'))"
        - "threshold条件: df[df['prediction_rank_pct'] >= threshold]"
        - "signalは全てBUY(1)を設定（ロングのみ戦略）"
        - "top_nとthreshold両方の条件を満たす必要がある"

  - id: apply_trading_costs
    description: "Apply swap rates and spread costs to calculate adjusted returns"
    impl: "apps.algo_trade_pipeline.transforms.backtest:apply_trading_costs"
    file_path: "transforms/backtest.py"
    parameters:
      - name: selected
        datatype_ref: SelectedCurrencyDataList
      - name: cost_config
        datatype_ref: TradingCostConfig
        optional: true
    return_type_ref: SelectedCurrencyDataWithCostsList
    spec_metadata:
      logic_steps:
        - "SelectedCurrencyDataListの各要素に対してコストを計算"
        - "symbolに対応するswap_rateとspread_costを設定から取得"
        - "adjusted_return = actual_return - swap_rate - spread_cost を計算"
        - "SelectedCurrencyDataWithCostsオブジェクトを生成してリスト化"
      implementation_hints:
        - "cost_configがNoneの場合はデフォルト値（0.0）を使用"
        - "swap_rateとspread_costはシンボルごとに異なる値を持つ辞書"
        - "cost_config.swap_rates.get(symbol, 0.0) で安全に取得"
        - "コストはリターンから差し引く（マイナス方向）"

  - id: simulate_buy_scenario
    description: "Run portfolio simulation with specified allocation method"
    impl: "apps.algo_trade_pipeline.transforms.backtest:simulate_buy_scenario"
    file_path: "transforms/backtest.py"
    parameters:
      - name: selected_currencies
        datatype_ref: SelectedCurrencyDataWithCostsList
      - name: allocation_method
        native: "builtins:str"
        literal:
          - "equal"
          - "weighted"
          - "risk_parity"
        default: "equal"
    return_type_ref: SimulationResult
    spec_metadata:
      logic_steps:
        - "各タイムスタンプごとに選択された通貨とそのadjusted_returnを集約"
        - "allocation_methodに応じてポートフォリオウェイトを計算"
        - "equal: 均等配分（1/N）"
        - "weighted: 予測値に比例した配分"
        - "risk_parity: ボラティリティ逆数に比例した配分"
        - "各タイムスタンプのポートフォリオリターンを計算（weighted sum）"
        - "時系列のポートフォリオリターンリストとequity curveを生成"
      implementation_hints:
        - "DataFrameでグループ化すると効率的"
        - "equity_curve = (1 + portfolio_returns).cumprod() で累積リターン計算"
        - "risk_parityの場合は過去ボラティリティの推定が必要"
        - "allocation_methodのバリデーションを実施"

  - id: calculate_performance_metrics
    description: "Calculate performance metrics (Sharpe, max drawdown, Calmar, etc.)"
    impl: "apps.algo_trade_pipeline.transforms.backtest:calculate_performance_metrics"
    file_path: "transforms/backtest.py"
    parameters:
      - name: simulation
        datatype_ref: SimulationResult
      - name: risk_free_rate
        native: "builtins:float"
        default: 0.0
    return_type_ref: PerformanceMetrics
    spec_metadata:
      logic_steps:
        - "portfolio_returnsから年率リターン（annual_return）を計算"
        - "年率ボラティリティ（annual_volatility）を計算"
        - "シャープレシオ = (annual_return - risk_free_rate) / annual_volatility"
        - "equity curveから最大ドローダウン（max_drawdown）を計算"
        - "カルマーレシオ = annual_return / abs(max_drawdown)"
        - "PerformanceMetricsオブジェクトとして返却"
      implementation_hints:
        - "年率換算係数: 日次データなら252、時間単位なら365*24"
        - "annual_return = mean(returns) * 年率換算係数"
        - "annual_volatility = std(returns) * sqrt(年率換算係数)"
        - "max_drawdown = min(equity_curve / cummax(equity_curve) - 1)"
        - "risk_free_rateは年率で指定されると想定"

# DAG stages with type-based auto-generation
dag_stages:
  # Phase 1: Market Data Ingestion (linear pipeline)
  - stage_id: "data_fetch"
    description: "Fetch market data from provider"
    selection_mode: "single"
    input_type: MarketDataIngestionConfig
    output_type: ProviderBatchCollection
    candidates:
      - fetch_yahoo_finance_ohlcv

  - stage_id: "normalization"
    description: "Normalize multi-provider data"
    selection_mode: "single"
    input_type: ProviderBatchCollection
    output_type: NormalizedOHLCVBundle
    candidates:
      - normalize_multi_provider

  - stage_id: "merge"
    description: "Merge into MultiIndex DataFrame"
    selection_mode: "single"
    input_type: NormalizedOHLCVBundle
    output_type: MultiAssetOHLCVFrame
    candidates:
      - merge_market_data_bundle

  - stage_id: "persist"
    description: "Persist market data snapshot"
    selection_mode: "single"
    input_type: MultiAssetOHLCVFrame
    output_type: MarketDataSnapshotMeta
    collect_output: true
    candidates:
      - persist_market_data_snapshot

  # Phase 2: Feature Engineering
  # NOTE: resample output uses pandas DataFrame (OHLCVFrame type_alias)
  - stage_id: "resample"
    description: "Resample OHLCV to target frequency"
    selection_mode: "single"
    input_type: MultiAssetOHLCVFrame
    output_type: OHLCVFrame
    candidates:
      - resample_ohlcv

  # Indicator calculation stage allows multiple selections
  - stage_id: "indicator_calculation"
    description: "Calculate technical indicators (select multiple)"
    selection_mode: "multiple"
    max_select: null  # unlimited - can use all indicators
    input_type: OHLCVFrame
    output_type: FeatureFrame  # Feature engineering outputs
    candidates:
      - calculate_rsi
      - calculate_adx
      - calculate_recent_return
      - calculate_volatility

  - stage_id: "target_generation"
    description: "Generate target variable (future return)"
    selection_mode: "single"
    input_type: FeatureFrame
    output_type: TargetFrame
    candidates:
      - calculate_future_return

  - stage_id: "feature_target_alignment"
    description: "Clean and align feature/target frames for model training"
    selection_mode: "single"
    input_type: TargetFrame
    output_type: AlignedFeatureTarget
    candidates:
      - clean_and_align_feature_target

  # Phase 3: Model Training & Prediction
  - stage_id: "model_training"
    description: "Train LightGBM with cross-validation"
    selection_mode: "single"
    input_type: AlignedFeatureTarget
    output_type: CVResult
    candidates:
      - train_lightgbm_cv

  - stage_id: "prediction_generation"
    description: "Generate OOS predictions from CV result"
    selection_mode: "single"
    input_type: CVResult
    output_type: PredictionDataList
    candidates:
      - generate_predictions

  # Phase 4: Backtest & Evaluation
  - stage_id: "ranking"
    description: "Rank predictions by score"
    selection_mode: "single"
    input_type: PredictionDataList
    output_type: RankedPredictionDataList
    candidates:
      - rank_predictions

  - stage_id: "filtering"
    description: "Filter top predictions and assign signals"
    selection_mode: "single"
    input_type: RankedPredictionDataList
    output_type: SelectedCurrencyDataList
    candidates:
      - filter_top_predictions

  - stage_id: "cost_application"
    description: "Apply trading costs (swap + spread)"
    selection_mode: "single"
    input_type: SelectedCurrencyDataList
    output_type: SelectedCurrencyDataWithCostsList
    candidates:
      - apply_trading_costs

  - stage_id: "simulation"
    description: "Run portfolio simulation"
    selection_mode: "single"
    input_type: SelectedCurrencyDataWithCostsList
    output_type: SimulationResult
    candidates:
      - simulate_buy_scenario

  - stage_id: "performance_evaluation"
    description: "Calculate performance metrics"
    selection_mode: "single"
    input_type: SimulationResult
    output_type: PerformanceMetrics
    collect_output: true
    candidates:
      - calculate_performance_metrics
